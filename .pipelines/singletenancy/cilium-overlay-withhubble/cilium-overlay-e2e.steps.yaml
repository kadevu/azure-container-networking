parameters:
  name: ""
  clusterName: ""
  testHubble: false
  scaleup: ""
  nightly: false

steps:

  - bash: |
      go version
      go env
      mkdir -p '$(GOBIN)'
      mkdir -p '$(GOPATH)/pkg'
      mkdir -p '$(modulePath)'
      echo '##vso[task.prependpath]$(GOBIN)'
      echo '##vso[task.prependpath]$(GOROOT)/bin'
    name: "GoEnv"
    displayName: "Set up the Go environment"

  - task: KubectlInstaller@0
    inputs:
      kubectlVersion: latest

  - task: AzureCLI@2
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        make -C ./hack/aks set-kubeconf AZCLI=az CLUSTER=${{ parameters.clusterName }}
        ls -lah
        # makefile manages cilium version
        unset DIR
        unset CILIUM_VERSION_TAG
        make -C ./hack/aks deploy-cilium-hubble
        export CILIUM_LOG_COLLECTOR_IMAGE_REGISTRY=acnpublic.azurecr.io
        export CILIUM_LOG_COLLECTOR_VERSION_TAG=$(make cilium-log-collector-version)
        make -C ./hack/aks add-cilium-log-collector
    name: "installCilium"
    displayName: "Install Cilium on AKS Overlay"

  - template: ../../templates/cilium-cli.yaml

  - script: |
      echo "Start Azilium E2E Tests on Overlay Cluster"
      if [ "$CILIUM_VERSION_TAG" = "cilium-nightly-pipeline" ]
      then
          CNS=$(CNS_VERSION) IPAM=$(AZURE_IPAM_VERSION) && echo "Running nightly"
      else
          CNS=$(make cns-version) IPAM=$(make azure-ipam-version)
      fi
      sudo -E env "PATH=$PATH" make test-load \
        SCALE_UP=32 OS_TYPE=linux VALIDATE_STATEFILE=true \
        INSTALL_CNS=true INSTALL_OVERLAY=true CLEANUP=true \
        AZURE_IPAM_VERSION=$(AZURE_IPAM_VERSION) CNS_VERSION=$(CNS_VERSION) \
        IPAM_IMAGE_NAME_OVERRIDE=$(IPAM_IMAGE_NAME_OVERRIDE) CNS_IMAGE_NAME_OVERRIDE=$(CNS_IMAGE_NAME_OVERRIDE)
    retryCountOnTaskFailure: 3
    name: "aziliumTest"
    displayName: "Run Azilium E2E on AKS Overlay"

  - script: |
      kubectl get pods -A
      echo "Waiting < 2 minutes for cilium to be ready"
      # Ensure Cilium is ready Xm\Xs
      cilium status --wait --wait-duration 2m
      kubectl get crd -A
    retryCountOnTaskFailure: 3
    name: "CiliumStatus"
    displayName: "Cilium Status"

  - task: AzureCLI@2
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        kubectl get po -owide -A
        clusterName=${{ parameters.clusterName }}
        echo "Restarting nodes"
        for val in $(az vmss list -g MC_${clusterName}_${clusterName}_$(REGION_AKS_CLUSTER_TEST) --query "[].name" -o tsv); do
          make -C ./hack/aks restart-vmss AZCLI=az CLUSTER=${clusterName} REGION=$(REGION_AKS_CLUSTER_TEST) VMSS_NAME=${val}
        done
    displayName: "Restart Nodes"

  - task: AzureCLI@2
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        cd test/integration/load

        # Scale Cluster Up/Down to confirm functioning CNS
        ITERATIONS=2 SCALE_UP=${{ parameters.scaleup }} OS_TYPE=linux go test -count 1 -timeout 30m -tags load -run ^TestLoad$
        kubectl get pods -owide -A

        cd ../../..
        echo "Validating Node Restart"
        make test-validate-state OS_TYPE=linux RESTART_CASE=true
        kubectl delete ns load-test
    displayName: "Validate Node Restart"
    retryCountOnTaskFailure: 3

  - template: ../../templates/cilium-connectivity-tests.yaml

  - ${{ if eq( parameters['testHubble'], true) }}:
      - script: |
          echo "enable Hubble metrics server"
          # makefile manages cilium version
          unset DIR
          unset CILIUM_VERSION_TAG
          make -C ./hack/aks deploy-hubble
          kubectl rollout restart ds cilium -n kube-system
          echo "wait <3 minutes for pods to be ready after restart"
          kubectl rollout status ds cilium -n kube-system --timeout=3m
          kubectl get pods -Aowide
          echo "verify Hubble metrics endpoint is usable"
          go test ./test/integration/networkobservability -v -tags=networkobservability
        retryCountOnTaskFailure: 3
        name: "HubbleConnectivityTests"
        displayName: "Run Hubble Connectivity Tests"

  - ${{if eq( parameters['nightly'], true) }}:
    - template: ../../templates/cilium-nightly-checks.yaml
  - ${{else }}:
    - script: |
        set -e
        echo "validate pod IP assignment and check systemd-networkd restart"
        kubectl get pod -owide -A
        ciliumNamespace=`kubectl get ns | grep cilium-test | awk '{print $1}'`

        make test-validate-state

        echo "delete cilium connectivity test resources and re-validate state"
        for namespace in ${ciliumNamespace}; do
          kubectl delete ns ${namespace}
        done
        kubectl get pod -owide -A

        make test-validate-state
      name: "validatePods"
      displayName: "Validate Pods"

  - script: |
      echo "Run wireserver and metadata connectivity Tests"
      bash test/network/wireserver_metadata_test.sh
    retryCountOnTaskFailure: 3
    name: "WireserverMetadataConnectivityTests"
    displayName: "Run Wireserver and Metadata Connectivity Tests"

  - script: |
      cd hack/scripts
      chmod +x async-delete-test.sh
      ./async-delete-test.sh
      if ! [ -z $(kubectl -n kube-system get ds  azure-cns | grep non-existing) ]; then
        kubectl -n kube-system patch daemonset azure-cns --type json -p='[{"op": "remove", "path": "/spec/template/spec/nodeSelector/non-existing"}]'
      fi
    name: "testAsyncDelete"
    displayName: "Verify Async Delete when CNS is down"

  - template: ../../templates/cilium-mtu-check.yaml

  - script: |
      ARTIFACT_DIR=$(Build.ArtifactStagingDirectory)/test-output/
      echo $ARTIFACT_DIR
      sudo rm -rf $ARTIFACT_DIR
      sudo rm -rf test/integration/logs
    name: "Cleanupartifactdir"
    displayName: "Cleanup artifact dir"
    condition: always()
